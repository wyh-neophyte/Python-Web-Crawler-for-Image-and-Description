{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8327e12-aacd-43d8-be1f-ec4b257e7000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "import cloudscraper\n",
    "from lxml import html, etree\n",
    "import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fa54af-f40e-45e7-a171-7c90606eb72b",
   "metadata": {},
   "source": [
    "# download sitemap.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958ead00-9255-4f20-a016-318ed7a0c196",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scraper = cloudscraper.create_scraper()\n",
    "sitemap_url = \"https://animalia.bio/sitemap.xml\"\n",
    "sitemap_response = scraper.get(sitemap_url)\n",
    "if sitemap_response.status_code == 200 and \"<loc>\" in sitemap_response.text:\n",
    "    os.makedirs(f'raw-data', exist_ok=True)\n",
    "    with open(\"raw-data/sitemap.xml\", \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(sitemap_response.text)\n",
    "        print(sitemap_response.text)\n",
    "else:\n",
    "    print(\"blocked by Cloudflare\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3718cd59-ec7a-4db6-8fc6-fa0ca549500a",
   "metadata": {},
   "source": [
    "# download xmls according to the sitemap.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6ce4aa-28f5-4b8f-8481-c1d71dbb94f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('raw-data/sitemap.xml', 'r') as file:\n",
    "    content = ''.join(file.readlines())\n",
    "tree = html.fromstring(content.encode('utf-8'))\n",
    "urls = tree.xpath(\"//loc/text()\")\n",
    "\n",
    "for url in urls:\n",
    "    response = scraper.get(url)\n",
    "    if response.status_code == 200:\n",
    "        file_name = url.split('/')[-1]\n",
    "        os.makedirs(f'raw-data/{file_name.split(\".\")[0]}', exist_ok=True)\n",
    "        with open(f'raw-data/{file_name.split(\".\")[0]}/{file_name}', \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(response.text)\n",
    "        print(f'raw-data/{file_name.split(\".\")[0]}/{file_name}')\n",
    "    else:\n",
    "        print(\"blocked by Cloudflare\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee90e117-9682-450d-8736-1c3116154540",
   "metadata": {},
   "source": [
    "## download the image-text pairs from the urls in collections.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c056c4c2-5dec-461b-8234-831b9db821e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subsets = [item.split('/')[-1] for item in glob.glob('raw-data/*') if not item.endswith('.xml')]\n",
    "print(subsets)\n",
    "for subset in subsets:\n",
    "    with open(f'raw-data/{subset}/{subset}.xml', 'r') as file:\n",
    "        content = ''.join(file.readlines())\n",
    "    tree = html.fromstring(content.encode('utf-8'))\n",
    "    urls = tree.xpath(\"//loc/text()\")\n",
    "\n",
    "    scraper = cloudscraper.create_scraper()\n",
    "    for url in urls:\n",
    "        response = scraper.get(url)\n",
    "        if response.status_code == 200:\n",
    "            file_name = url.split('/')[-1]\n",
    "            if not file_name.endswith('.xml'):\n",
    "                file_name += '.xml'\n",
    "            os.makedirs(f'raw-data/{subset}/{file_name.split(\".\")[0]}', exist_ok=True)\n",
    "            with open(f'raw-data/{subset}/{file_name.split(\".\")[0]}/{file_name}', \"w\", encoding=\"utf-8\") as file:\n",
    "                file.write(response.text)\n",
    "                print(f'raw-data/{subset}/{file_name.split(\".\")[0]}/{file_name}')\n",
    "                time.sleep(1)\n",
    "        else:\n",
    "            print(\"blocked by Cloudflare\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efee26b8-eee8-4aa9-97a9-f9cdc0fe78eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subsets = [item.split('\\\\')[-1] for item in glob.glob('animals/*')]\n",
    "for subset in tqdm.tqdm(subsets):\n",
    "    if os.path.exists(f'animals/{subsubset}/descriptions.json'):\n",
    "        continue\n",
    "\n",
    "    with open(f'animals/{subset}/{subset}.xml', 'r', encoding='utf-8') as file:\n",
    "        content = ''.join(file.readlines())\n",
    "        tree = html.fromstring(content.encode('utf-8'))\n",
    "\n",
    "        # extract urls\n",
    "        img_urls = []\n",
    "        img_urls += tree.xpath('//div[@class=\"s-char-img open-gallery\"]/img/@src')\n",
    "        img_urls += tree.xpath('//div[@class=\"s-gallery-item s-gallery-item--right open-gallery\"]/img/@src')\n",
    "        for img_url in img_urls:\n",
    "            scraper = cloudscraper.create_scraper()\n",
    "            response = scraper.get(img_url)\n",
    "            if response.status_code == 200:\n",
    "                file_name = os.path.basename(img_url).split(\"?\")[0]\n",
    "                file_path = f'animals/{subset}/{file_name}'\n",
    "                with open(file_path, \"wb\") as f:\n",
    "                    f.write(response.content)\n",
    "            time.sleep(1)\n",
    "\n",
    "        # extract general descriptions\n",
    "        general_descriptions = tree.xpath('//div[@class=\"s-char-text\"]/p//text()')\n",
    "        general_descriptions = ''.join(general_descriptions).strip()\n",
    "\n",
    "        # extract appearance descriptions\n",
    "        appearance_descriptions = tree.xpath('//div[@class=\"s-appearance-block\"]/p//text()')\n",
    "        appearance_descriptions = ''.join(appearance_descriptions).strip()\n",
    "\n",
    "        # extract distribution descriptions\n",
    "        distribution_descriptions = tree.xpath('//div[@class=\"s-distr-content\"]/p//text()')\n",
    "        distribution_descriptions = ''.join(distribution_descriptions).strip()\n",
    "\n",
    "        # extract lifestyle descriptions\n",
    "        lifestyle_descriptions = tree.xpath('//div[@class=\"s-habbit-content\"]/p//text()')\n",
    "        lifestyle_descriptions = ''.join(lifestyle_descriptions).strip()\n",
    "\n",
    "        # extract diet descriptions\n",
    "        diet_descriptions = tree.xpath('//div[@class=\"s-diet-block\"]/div[@class=\"row\"]/div[@class=\"col-lg-8\"]/p//text()')\n",
    "        diet_descriptions = ''.join(diet_descriptions).strip()\n",
    "\n",
    "        # extract mating descriptions\n",
    "        mating_descriptions = tree.xpath('//div[@class=\"s-mating-text\"]/p//text()')\n",
    "        mating_descriptions = ''.join(mating_descriptions).strip()\n",
    "\n",
    "        # extract population descriptions\n",
    "        population_descriptions = tree.xpath('//div[@class=\"s-population-content\"]/p//text()')\n",
    "        population_descriptions = ''.join(population_descriptions).strip()\n",
    "\n",
    "        # gather all information and save to json file\n",
    "        descriptions = {\n",
    "            'general_descriptions': general_descriptions,\n",
    "            'appearance_descriptions': appearance_descriptions,\n",
    "            'distribution_descriptions': distribution_descriptions,\n",
    "            'lifestyle_descriptions': lifestyle_descriptions,\n",
    "            'diet_descriptions': diet_descriptions,\n",
    "            'mating_descriptions': mating_descriptions,\n",
    "            'population_descriptions': population_descriptions\n",
    "        }\n",
    "        with open(f'animals/{subset}/descriptions.json', 'w', encoding='utf-8') as file:\n",
    "            json.dump(descriptions, file, indent=4)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2bd7b9-8da3-4ca2-ae28-eabd6801efbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
